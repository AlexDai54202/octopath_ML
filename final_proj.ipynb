{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octopath Traveler Weakness Analysis\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Octopath Traveler is a video game. All enemies have a set of weaknesses, and hitting those weaknesses deal 1.5x damage (when the enemy is not broken). Additionally, enemies have shields, and only by hitting weaknesses can you break enemy shields. When an enemy shield is broken, the enemy loses their action(s) for the current turn, and their next turn before they get their action back. Additionally, when an enemy shield is broken, they are subject to a \"broken\" state until they recover their shield, making them take x2 incoming damage.\n",
    "\n",
    "In this project, I will create a CNN to predict enemy weaknesses by their sprite.\n",
    "\n",
    "Of course, this is hardly the most pragmatic topic, and I am not arguing that this is going to be extremely helpful (considering datamines for every enemy weakness already exists), but this can serve as a good introduction to CNNs and transfer learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code - Part 1: Representing data\n",
    "\n",
    "I will take EnemyDB, join it with the CharacterResourceDB table, and associate each enemy's weakness with a set of weaknesses and a sprite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemyDB = json.load(open('EnemyDB.json'))[0]\n",
    "resourceDB = json.load(open('CharacterResourceDB.json'))[0]\n",
    "textDB = json.load(open('GameTextEN.json', encoding=\"utf8\"))[0]\n",
    "\n",
    "del enemyDB['export_type']\n",
    "del resourceDB['export_type']\n",
    "del textDB['export_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemydf = pd.DataFrame.from_dict(enemyDB).transpose()\n",
    "resourcedf = pd.DataFrame.from_dict(resourceDB).transpose()\n",
    "textdf = pd.DataFrame.from_dict(textDB).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = enemydf.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literally all these columns, except for the enemy name and weakness should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemydf = enemydf.drop(cols.drop(['DisplayNameID_151_570F1B1240B0BB42C31AA7A4F6CFAF72','ResourceLabel_295_2D43957442A6F48343BB639C79635FAE','AttributeResist_282_87881AFB4F4DD148EA692D8F63B73E16','WeaponResist_283_0BB9356646F9B928F5FC1584A458ABBC']), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we remove all names that are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemydf = enemydf.mask(enemydf.eq('None')).dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we one-hot encode.\n",
    "\n",
    "Attributes go: Fire, Ice, Lightning, Wind, Light, Dark.\n",
    "\n",
    "Weapons go: Sword, Spear, Dagger, Axe, Bow, Staff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DisplayNameID_151_570F1B1240B0BB42C31AA7A4F6CFAF72</th>\n",
       "      <th>ResourceLabel_295_2D43957442A6F48343BB639C79635FAE</th>\n",
       "      <th>AttributeResist_282_87881AFB4F4DD148EA692D8F63B73E16</th>\n",
       "      <th>WeaponResist_283_0BB9356646F9B928F5FC1584A458ABBC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enemy_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENE_BOS_WAR_C01_010</th>\n",
       "      <td>ENN_BOS_WAR_C01_010</td>\n",
       "      <td>ENE_BOS_WAR_C01_010</td>\n",
       "      <td>[EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...</td>\n",
       "      <td>[EATTRIBUTE_RESIST::eWEAK, EATTRIBUTE_RESIST::...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENE_BOS_WAR_C01_020</th>\n",
       "      <td>ENN_BOS_WAR_C01_020</td>\n",
       "      <td>ENE_BOS_WAR_C01_020</td>\n",
       "      <td>[EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...</td>\n",
       "      <td>[EATTRIBUTE_RESIST::eWEAK, EATTRIBUTE_RESIST::...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENE_BOS_WAR_C02_010</th>\n",
       "      <td>ENN_BOS_WAR_C02_010</td>\n",
       "      <td>ENE_BOS_WAR_C02_010</td>\n",
       "      <td>[EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...</td>\n",
       "      <td>[EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENE_BOS_WAR_C02_020</th>\n",
       "      <td>ENN_BOS_WAR_C02_020</td>\n",
       "      <td>ENE_BOS_WAR_C02_020</td>\n",
       "      <td>[EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...</td>\n",
       "      <td>[EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENE_BOS_WAR_C04_010</th>\n",
       "      <td>ENN_BOS_WAR_C04_010</td>\n",
       "      <td>ENE_BOS_WAR_C04_010</td>\n",
       "      <td>[EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...</td>\n",
       "      <td>[EATTRIBUTE_RESIST::eWEAK, EATTRIBUTE_RESIST::...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DisplayNameID_151_570F1B1240B0BB42C31AA7A4F6CFAF72  \\\n",
       "Enemy_ID                                                                 \n",
       "ENE_BOS_WAR_C01_010                                ENN_BOS_WAR_C01_010   \n",
       "ENE_BOS_WAR_C01_020                                ENN_BOS_WAR_C01_020   \n",
       "ENE_BOS_WAR_C02_010                                ENN_BOS_WAR_C02_010   \n",
       "ENE_BOS_WAR_C02_020                                ENN_BOS_WAR_C02_020   \n",
       "ENE_BOS_WAR_C04_010                                ENN_BOS_WAR_C04_010   \n",
       "\n",
       "                    ResourceLabel_295_2D43957442A6F48343BB639C79635FAE  \\\n",
       "Enemy_ID                                                                 \n",
       "ENE_BOS_WAR_C01_010                                ENE_BOS_WAR_C01_010   \n",
       "ENE_BOS_WAR_C01_020                                ENE_BOS_WAR_C01_020   \n",
       "ENE_BOS_WAR_C02_010                                ENE_BOS_WAR_C02_010   \n",
       "ENE_BOS_WAR_C02_020                                ENE_BOS_WAR_C02_020   \n",
       "ENE_BOS_WAR_C04_010                                ENE_BOS_WAR_C04_010   \n",
       "\n",
       "                    AttributeResist_282_87881AFB4F4DD148EA692D8F63B73E16  \\\n",
       "Enemy_ID                                                                   \n",
       "ENE_BOS_WAR_C01_010  [EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...     \n",
       "ENE_BOS_WAR_C01_020  [EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...     \n",
       "ENE_BOS_WAR_C02_010  [EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...     \n",
       "ENE_BOS_WAR_C02_020  [EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...     \n",
       "ENE_BOS_WAR_C04_010  [EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...     \n",
       "\n",
       "                     WeaponResist_283_0BB9356646F9B928F5FC1584A458ABBC  \n",
       "Enemy_ID                                                                \n",
       "ENE_BOS_WAR_C01_010  [EATTRIBUTE_RESIST::eWEAK, EATTRIBUTE_RESIST::...  \n",
       "ENE_BOS_WAR_C01_020  [EATTRIBUTE_RESIST::eWEAK, EATTRIBUTE_RESIST::...  \n",
       "ENE_BOS_WAR_C02_010  [EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...  \n",
       "ENE_BOS_WAR_C02_020  [EATTRIBUTE_RESIST::eNONE, EATTRIBUTE_RESIST::...  \n",
       "ENE_BOS_WAR_C04_010  [EATTRIBUTE_RESIST::eWEAK, EATTRIBUTE_RESIST::...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enemydf.index.name = 'Enemy_ID'\n",
    "enemydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemydf[['Magic', 'Fire','Ice','Lightning','Wind','Light','Dark']] = pd.DataFrame(enemydf['AttributeResist_282_87881AFB4F4DD148EA692D8F63B73E16'].tolist(), index=enemydf.index)\n",
    "enemydf[['Sword', 'Spear', 'Dagger', 'Axe', 'Bow', 'Staff','Physical']] = pd.DataFrame(enemydf['WeaponResist_283_0BB9356646F9B928F5FC1584A458ABBC'].tolist(), index=enemydf.index)\n",
    "\n",
    "enemydf = enemydf.drop(['AttributeResist_282_87881AFB4F4DD148EA692D8F63B73E16',\t'WeaponResist_283_0BB9356646F9B928F5FC1584A458ABBC','Magic','Physical'],axis=1)\n",
    "enemydf = enemydf.rename({'DisplayNameID_151_570F1B1240B0BB42C31AA7A4F6CFAF72':'DisplayName','ResourceLabel_295_2D43957442A6F48343BB639C79635FAE':'ResourceLabel'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_if_possible(name):\n",
    "    try:\n",
    "        return textdf.loc[name]['Text']['string']\n",
    "    except:\n",
    "        return 'None'\n",
    "\n",
    "enemydf['DisplayName'] = enemydf['DisplayName'].apply(find_if_possible)\n",
    "enemydf = enemydf.drop(enemydf[enemydf['DisplayName'].str.contains('None')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"EATTRIBUTE_RESIST::eWEAK\":1,\"EATTRIBUTE_RESIST::eNONE\":0}\n",
    "enemydf = enemydf.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enemy_ID</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>ResourceLabel</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Ice</th>\n",
       "      <th>Lightning</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Light</th>\n",
       "      <th>Dark</th>\n",
       "      <th>Sword</th>\n",
       "      <th>Spear</th>\n",
       "      <th>Dagger</th>\n",
       "      <th>Axe</th>\n",
       "      <th>Bow</th>\n",
       "      <th>Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENE_BOS_WAR_C01_010</td>\n",
       "      <td>Ritsu Mishuyo</td>\n",
       "      <td>ENE_BOS_WAR_C01_010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENE_BOS_WAR_C01_020</td>\n",
       "      <td>Ritsu's Footman</td>\n",
       "      <td>ENE_BOS_WAR_C01_020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENE_BOS_WAR_C02_010</td>\n",
       "      <td>Bandelam the Reaper</td>\n",
       "      <td>ENE_BOS_WAR_C02_010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENE_BOS_WAR_C02_020</td>\n",
       "      <td>Borneau</td>\n",
       "      <td>ENE_BOS_WAR_C02_020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENE_BOS_WAR_C04_010</td>\n",
       "      <td>Rai Mei</td>\n",
       "      <td>ENE_BOS_WAR_C04_010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Enemy_ID          DisplayName        ResourceLabel  Fire  Ice  \\\n",
       "0  ENE_BOS_WAR_C01_010        Ritsu Mishuyo  ENE_BOS_WAR_C01_010     1    0   \n",
       "1  ENE_BOS_WAR_C01_020      Ritsu's Footman  ENE_BOS_WAR_C01_020     1    0   \n",
       "2  ENE_BOS_WAR_C02_010  Bandelam the Reaper  ENE_BOS_WAR_C02_010     1    0   \n",
       "3  ENE_BOS_WAR_C02_020              Borneau  ENE_BOS_WAR_C02_020     0    0   \n",
       "4  ENE_BOS_WAR_C04_010              Rai Mei  ENE_BOS_WAR_C04_010     1    0   \n",
       "\n",
       "   Lightning  Wind  Light  Dark  Sword  Spear  Dagger  Axe  Bow  Staff  \n",
       "0          0     0      0     0      1      0       0    0    1      0  \n",
       "1          0     0      0     0      1      1       0    0    1      0  \n",
       "2          0     0      1     0      0      1       1    1    0      0  \n",
       "3          0     0      0     0      0      0       0    0    0      0  \n",
       "4          0     0      1     0      1      0       0    0    0      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enemydf = enemydf.reset_index()\n",
    "enemydf.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to combine with resourcedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_if_possible(name):\n",
    "    try:\n",
    "        return resourcedf.loc[name]['ActionOrderIconL']['asset_path_name']\n",
    "    except:\n",
    "        return 'None'\n",
    "\n",
    "enemydf['asset_path'] = enemydf['ResourceLabel'].apply(find_if_possible)\n",
    "enemydf = enemydf.drop(enemydf[enemydf['asset_path'] == 'None'].index)\n",
    "enemydf = enemydf.drop('ResourceLabel',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemydf['asset_path'] = enemydf['asset_path'].apply(lambda x: \".\\\\enemyicons\\\\\" + (x[57:])[:int(len(x[57:])/2)] + '.png')\n",
    "# edge case:\n",
    "enemydf = enemydf.drop(enemydf[enemydf['asset_path']=='.\\\\enemyicons\\\\UiTX_Battle_Oder_Select_Ritsu.png'].index)\n",
    "enemydf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemydf.to_csv('dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: CNN creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming all images are of the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "size = (0,0)\n",
    "for i in df['asset_path']:\n",
    "    if os.path.exists(i):\n",
    "        if Image.open(i).size != size:\n",
    "            print(Image.open(i).size)\n",
    "            size = Image.open(i).size\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a AMD GPU so I can't do much about this ):\n",
    "\n",
    "For now I will continue writing the code, assuming I can train with CUDA avalible, and on a later date I will train with a GPU from UMIACS once I figure out how to connect to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images: (640, 128, 128, 3)\n",
      "Shape of labels: (640, 12)\n",
      "Shape of images: (72, 128, 128, 3)\n",
      "Shape of labels: (72, 12)\n"
     ]
    }
   ],
   "source": [
    "import keras.utils as image\n",
    "\n",
    "def arrange_data(dfin):\n",
    "    \n",
    "    image_data = []\n",
    "    img_paths = np.asarray(dfin['asset_path'])\n",
    "    \n",
    "    for i in range(len(img_paths)):\n",
    "        img = image.load_img(img_paths[i],target_size=(128, 128, 3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255\n",
    "        image_data.append(img)\n",
    "        \n",
    "        \n",
    "    X = np.array(image_data)\n",
    "    Y = np.array(dfin[['Fire','Ice','Lightning','Wind','Light','Dark','Sword','Spear','Dagger','Axe','Bow','Staff']])\n",
    "    \n",
    "    print(\"Shape of images:\", X.shape)\n",
    "    print(\"Shape of labels:\", Y.shape)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.1)\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train = arrange_data(dfin = train)\n",
    "\n",
    "\n",
    "x_test, y_test = arrange_data(dfin = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              8389632   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12)                12300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,116,620\n",
      "Trainable params: 15,481,356\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex Dai\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\legacy\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "C:\\Users\\Alex Dai\\AppData\\Local\\Temp\\ipykernel_14072\\4022961056.py:33: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(aug.flow(x_train, y_train, batch_size=BS),validation_data=(x_test, y_test), steps_per_epoch=len(x_train) // BS, epochs=EPOCHS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 19s 2s/step - loss: 0.6702 - accuracy: 0.0641 - val_loss: 0.6095 - val_accuracy: 0.0139\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.6250 - accuracy: 0.0406 - val_loss: 0.6057 - val_accuracy: 0.0417\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.6207 - accuracy: 0.0406 - val_loss: 0.6019 - val_accuracy: 0.0139\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.0391"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m# data augmentation to reduce overfit\u001b[39;00m\n\u001b[0;32m     31\u001b[0m aug \u001b[39m=\u001b[39m ImageDataGenerator(rotation_range\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, zoom_range\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m,width_shift_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, height_shift_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, shear_range\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m,horizontal_flip\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fill_mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(aug\u001b[39m.\u001b[39;49mflow(x_train, y_train, batch_size\u001b[39m=\u001b[39;49mBS),validation_data\u001b[39m=\u001b[39;49m(x_test, y_test), steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(x_train) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m BS, epochs\u001b[39m=\u001b[39;49mEPOCHS)\n\u001b[0;32m     35\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mModel_4d.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:2636\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2624\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2625\u001b[0m \n\u001b[0;32m   2626\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2627\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2628\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2629\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2630\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2631\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2632\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2633\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2634\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2635\u001b[0m )\n\u001b[1;32m-> 2636\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   2637\u001b[0m     generator,\n\u001b[0;32m   2638\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   2639\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   2640\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2641\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2642\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   2643\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   2644\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   2645\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2646\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2647\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2648\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2649\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   2650\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   2651\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1729\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1715\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1716\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1717\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1727\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1728\u001b[0m     )\n\u001b[1;32m-> 1729\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1730\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1731\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1732\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1733\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1734\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1735\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1736\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1737\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1738\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1739\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1740\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1741\u001b[0m )\n\u001b[0;32m   1742\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1743\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1744\u001b[0m }\n\u001b[0;32m   1745\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:2072\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   2069\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   2070\u001b[0m ):\n\u001b[0;32m   2071\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2072\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   2073\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2074\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    931\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    932\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    935\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras import models, layers, optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# freeze last 4 layers\n",
    "for layer in vgg_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(vgg_conv)\n",
    "\n",
    "num_classes = 12\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "EPOCHS=50\n",
    "BS = 64\n",
    "\n",
    "# data augmentation to reduce overfit\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "history = model.fit_generator(aug.flow(x_train, y_train, batch_size=BS),validation_data=(x_test, y_test), steps_per_epoch=len(x_train) // BS, epochs=EPOCHS)\n",
    "\n",
    "model.save('Model_4d.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
